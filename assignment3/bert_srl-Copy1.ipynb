{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925d7490-eceb-47ec-afd4-058185dd5907",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:02:57.628848300Z",
     "start_time": "2024-03-02T08:02:52.567609900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token can be pasted using 'Right-Click'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\katko\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, interpreter_login\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4185369c2aeddffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:09.167477300Z",
     "start_time": "2024-03-02T08:03:08.756115500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"token_classification_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e66291332607cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:19.819027300Z",
     "start_time": "2024-03-02T08:03:19.802028300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc992a4-f301-4e59-9ba4-fabca8814a4f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3acb54-8a43-45a3-8993-c784282d739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import extract_data_from_conll_extended\n",
    "extract_data_from_conll_extended(\"data/en_ewt-up-test.conllu\", \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f57dffa9a221e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:50.718490300Z",
     "start_time": "2024-03-02T08:03:49.564125200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34afb605042849ef9c84b03360c57019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec23fb32b144b9c9ea06baa2ff228cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['word', 'arguments', 'predicate_position', 'predicate'],\n",
       "        num_rows: 40482\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['word', 'arguments', 'predicate_position', 'predicate'],\n",
       "        num_rows: 4799\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "datasets = load_dataset('json', data_files={'train': 'train.json', 'test': 'test.json'})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1314a051618b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:06.072630300Z",
     "start_time": "2024-03-02T08:04:06.055630900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': ['Al',\n",
       "  '-',\n",
       "  'Zaman',\n",
       "  ':',\n",
       "  'American',\n",
       "  'forces',\n",
       "  'killed',\n",
       "  'Shaikh',\n",
       "  'Abdullah',\n",
       "  'al',\n",
       "  '-',\n",
       "  'Ani',\n",
       "  ',',\n",
       "  'the',\n",
       "  'preacher',\n",
       "  'at',\n",
       "  'the',\n",
       "  'mosque',\n",
       "  'in',\n",
       "  'the',\n",
       "  'town',\n",
       "  'of',\n",
       "  'Qaim',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'Syrian',\n",
       "  'border',\n",
       "  '.'],\n",
       " 'arguments': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARG0',\n",
       "  'V',\n",
       "  'ARG1',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARGM-LOC',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_'],\n",
       " 'predicate_position': 7,\n",
       " 'predicate': 'kill.01'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6fae141fbc0385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:23.990387200Z",
     "start_time": "2024-03-02T08:04:23.975385900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a6b7ec65470697f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:29.769044100Z",
     "start_time": "2024-03-02T08:04:29.715044800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>arguments</th>\n",
       "      <th>predicate_position</th>\n",
       "      <th>predicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[What, s, your, favorite, part, about, trail, riding, ?]</td>\n",
       "      <td>[_, _, _, _, _, _, ARGM-LOC, V, _]</td>\n",
       "      <td>8</td>\n",
       "      <td>ride.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[If, you, have, received, it, by, mistake, please, let, us, know, by, reply, and, then, delete, it, from, your, system, ;, you, should, not, copy, the, message, or, disclose, its, contents, to, anyone, .]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG0, ARGM-MOD, ARGM-NEG, V, _, ARG1, _, _, _, _, _, _, _]</td>\n",
       "      <td>25</td>\n",
       "      <td>copy.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Your, World, Series, in, Question, document, :, was, received, Kyle, Jones, /, US, /, AMERICAS, /, Equant, by, :, at, :, 01:00:51, PM, Today]</td>\n",
       "      <td>[_, _, _, _, _, _, _, V, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>8</td>\n",
       "      <td>be.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I, want, to, take, a, cruise, around, the, world, .]</td>\n",
       "      <td>[ARG0, _, _, ARGM-LVB, _, V, _, _, ARGM-DIR, _]</td>\n",
       "      <td>6</td>\n",
       "      <td>cruise.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[She, stole, the, information, and, gave, it, to, another, guy, that, did, all, the, work, .]</td>\n",
       "      <td>[ARG0, V, _, ARG1, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>2</td>\n",
       "      <td>steal.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[he, will, reassure, himself, that, no, other, animal, is, in, there, ,, and, that, no, other, animal, will, come, in, -, he, is, afraid, that, he, is, in, someone, else, 's, territory, when, he, is, in, a, new, house, .]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG0, _, V, _, _, _, _, _, _, _, ARG1, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>24</td>\n",
       "      <td>fear.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[I, figure, I, would, give, this, company, a, chance, .]</td>\n",
       "      <td>[_, _, ARG0, ARGM-MOD, V, _, ARG2, _, ARG1, _]</td>\n",
       "      <td>5</td>\n",
       "      <td>give.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[I, guess, that, tells, you, a, lot, .]</td>\n",
       "      <td>[_, _, ARG0, V, ARG2, _, ARG1, _]</td>\n",
       "      <td>4</td>\n",
       "      <td>tell.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[This, action, accelerated, the, utilities, ', move, toward, bankruptcy, and, forced, the, governor, to, move, the, state, into, the, power, -, buying, business, ., \"]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, ARG0, _, V, _, ARG1, _, _, _, _, _, ARG2, _, _]</td>\n",
       "      <td>15</td>\n",
       "      <td>move.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Under, President, Hu, Jintao, ,, Beijing, has, opened, out, to, New, Delhi, and, Prime, Minister, Wen, Jiabao, is, expected, to, visit, early, next, year, ,, making, friends, by, formally, accepting, Sikkim, as, part, of, India, and, backing, India, as, a, permanent, member, of, the, U.N., Security, Council, --, thus, leaving, Washington, as, the, only, one, of, the, \", permanent, five, \", that, has, not, yet, done, so, .]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG0, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V, ARG1, _, _, _, ARGM-PRD, _, _, _, _, _, _, _, ARGM-ADV, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>37</td>\n",
       "      <td>back.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e8cefa-fb3f-4334-8222-94b1e9641f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': ['Al',\n",
       "  '-',\n",
       "  'Zaman',\n",
       "  ':',\n",
       "  'American',\n",
       "  'forces',\n",
       "  'killed',\n",
       "  'Shaikh',\n",
       "  'Abdullah',\n",
       "  'al',\n",
       "  '-',\n",
       "  'Ani',\n",
       "  ',',\n",
       "  'the',\n",
       "  'preacher',\n",
       "  'at',\n",
       "  'the',\n",
       "  'mosque',\n",
       "  'in',\n",
       "  'the',\n",
       "  'town',\n",
       "  'of',\n",
       "  'Qaim',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'Syrian',\n",
       "  'border',\n",
       "  '.'],\n",
       " 'arguments': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARG0',\n",
       "  'V',\n",
       "  'ARG1',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARGM-LOC',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_'],\n",
       " 'predicate_position': 7,\n",
       " 'predicate': 'kill.01'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4a00a-883c-4620-b88d-fc3345d33e2d",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237f4338dcca93b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:22.530273900Z",
     "start_time": "2024-03-02T09:09:22.181391900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2996c7fe621ae6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:23.431553200Z",
     "start_time": "2024-03-02T09:09:23.411302100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4858eeaa61a663d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:24.745351400Z",
     "start_time": "2024-03-02T09:09:24.731350300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(instance):\n",
    "    def align(tokenized_input, labels):\n",
    "        word_ids = tokenized_input.word_ids()\n",
    "        aligned_labels = ['_'] * len(word_ids) \n",
    "        label_index = 0 \n",
    "        for i, word_id in enumerate(word_ids):\n",
    "            try:\n",
    "                if word_id is None:\n",
    "                    aligned_labels[i] = '[PAD]'\n",
    "                    continue \n",
    "                original_label = labels[word_id]\n",
    "                if original_label == '_':\n",
    "                    continue \n",
    "                if i == 0 or word_id != word_ids[i-1]:\n",
    "                    prefix = ''\n",
    "                else:\n",
    "                    prefix = ''\n",
    "                aligned_labels[i] = f'{prefix}{original_label}'\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        return aligned_labels\n",
    "    sentence = instance[\"word\"]\n",
    "    labels = instance[\"arguments\"]\n",
    "    tokenized_input = tokenizer(sentence, is_split_into_words=True)\n",
    "    predicate = instance['predicate']\n",
    "    predicate = tokenizer(predicate)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "    aligned_labels = align(tokenized_input, labels)\n",
    "    tokenized_input['input_ids'].extend(predicate['input_ids'][1:]), tokenized_input['attention_mask'].extend(predicate['attention_mask'][1:]), aligned_labels.extend(['[PAD]' for i in range(len(predicate['input_ids'][1:]))])\n",
    "    tokenized_input['labels'] = aligned_labels\n",
    "    \n",
    "    return tokenized_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92718ab9-217a-4d7a-b9c8-b91613a25c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40482\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets['train']))\n",
    "training_set = [tokenize(instance) for instance in datasets['train']]\n",
    "test_set = [tokenize(instance) for instance in datasets['test']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5e57dd6-e735-48a0-a182-37051b60fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102, 3102, 1012, 5890, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': ['[PAD]', '_', '_', '_', '_', '_', '_', 'ARG0', 'V', 'ARG1', 'ARG1', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'ARGM-LOC', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']}\n"
     ]
    }
   ],
   "source": [
    "sample = training_set[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287db1bd-6289-4b69-a9d4-1747102c5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Sequence, Value\n",
    "\n",
    "features = Features({\n",
    "    \"input_ids\": Sequence(feature=Value(dtype='int64')),\n",
    "    \"attention_mask\": Sequence(feature=Value(dtype='int64')),\n",
    "    \"labels\": Sequence(feature=Value(dtype='int64')),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e11cd7-3183-4cc0-8fe6-bbff43de4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = ['R-ARGM-ADJ', '_', 'ARGM-ADJ']\n",
    "label_list = list(set(label for instance in training_set for label in instance['labels'] + unseen))\n",
    "label_dict = {label:int(i) for i, label in enumerate(list(label_list))}\n",
    "label_dict['[PAD]'] = -100\n",
    "for instance in training_set:\n",
    "    instance['labels'] = [int(label_dict[label]) for label in instance['labels']]\n",
    "for instance in test_set:\n",
    "    instance['labels'] = [int(label_dict[label]) for label in instance['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f3c443-2b4c-4c1c-8201-69468605b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_dict({\"input_ids\": [item['input_ids'] for item in training_set],\n",
    "                             \"attention_mask\": [item['attention_mask'] for item in training_set],\n",
    "                             \"labels\": [item['labels'] for item in training_set]}, features=features)\n",
    "\n",
    "dataset_test = Dataset.from_dict({\"input_ids\": [item['input_ids'] for item in test_set],\n",
    "                             \"attention_mask\": [item['attention_mask'] for item in test_set],\n",
    "                             \"labels\": [item['labels'] for item in test_set]}, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94a7b34f43933b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:26.160324200Z",
     "start_time": "2024-03-02T09:09:26.148324700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102, 3102, 1012, 5890, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 56, 56, 56, 56, 56, 56, 16, 36, 34, 34, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 59, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, -100, -100, -100, -100, -100]}\n"
     ]
    }
   ],
   "source": [
    "#print(tokenized_input.word_ids())\n",
    "print(dataset_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e12cd73680f6939f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "# model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f010cfb-0ee7-4ba4-882e-5d83fe291505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358ca3f-63b2-4df9-83da-c7ca2964c75e",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d5094dc-1fb6-4706-8451-0c03449c7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68f52781-dbe4-4c67-bda0-5b641950faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27138d5c-1d91-4084-8675-b1f949b18e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katko\\AppData\\Local\\Temp\\ipykernel_39316\\2951164050.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2b9e9f9-0c5c-48b8-98c1-eaf836b71064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-REC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGA seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-MOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG1-DSP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-PRD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG1-DSP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-NEG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-DIS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-LVB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ADV': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARG0': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG1': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG1-DSP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARG2': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG3': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG4': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-ADJ': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-ADV': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-CAU': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-COM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-CXN': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-DIR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-EXT': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-GOL': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-LOC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-MNR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-PRP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-PRR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-TMP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'CAU': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'COM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'CXN': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'DIR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'DIS': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'DSP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'EXT': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'GOL': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'LOC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'LVB': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'MNR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'MOD': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'NEG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PAD]': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PRD': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PRP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PRR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'REC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG0': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG1': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG2': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG3': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG4': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG5': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RGA': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'TMP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'V': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " '_': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(label_list)\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e7af19e-b45d-4a9a-a650-1c0d8afee453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd6bd6-fcb3-48e9-8a79-ac5a80888ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eb16b28-bddf-4545-ac99-010ea003d435",
   "metadata": {},
   "source": [
    "## Training the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92f6ca14-aed3-41cd-b002-a0d71a09972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_model(pickles):\n",
    "    '''\n",
    "    Input: string name with .pickle extension. Must be present in working directory. Check with 'pwd' command\n",
    "    Loads pretrained model variable from pickle file at filepath(pickle).\n",
    "    '''\n",
    "    with open(pickles, 'rb') as p:\n",
    "        return pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d73fac29-8efb-44dc-b30d-fe835f003289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type 'load' to load a model from the directory, else press enter load\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, DistilBertForTokenClassification\n",
    "if input(\"Type 'load' to load a model from the directory, else press enter\") == 'load':\n",
    "    # basic_model = load_model('basic_bert.pickle')\n",
    "    basic_model = DistilBertForTokenClassification.from_pretrained(\"Jing1113/distilbert-base-uncased-finetuned-srl\")\n",
    "\n",
    "else:\n",
    "    basic_model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc17c6d4-ca25-48cd-94fe-2fe9496e9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    basic_model,\n",
    "    args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5a708-f4bb-43d4-bd0f-78e115fd218a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f362db0a-f267-40b5-beb4-a92fef415f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cce2d7de-5e13-4521-b519-56392cb81c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "type 'y' to train model, press enter to skip \n"
     ]
    }
   ],
   "source": [
    "if input(\"type 'y' to train model, press enter to skip\") == 'y':\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f83ee8-6e2e-4506-91bf-77293f950e57",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519ed02-45b5-4d16-9b5d-712817ba394c",
   "metadata": {},
   "source": [
    "#### This part is unfinished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48ef0311-7415-4a16-a8c8-f94e160fac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "x, y = dataset_test.select_columns(['input_ids','attention_mask']), dataset_test.select_columns(['labels'])\n",
    "# basic_model.eval()\n",
    "# with torch.no_grad():\n",
    "predictions, labels, _ = trainer.predict(x)\n",
    "# predictions = np.argmax(predictions, axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d49b21d-1404-4e90-9934-6cc9e82b2195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19306e48-f0ba-4df8-aeff-fd418f463e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7663c6a3-f374-4ae9-b834-6c9ed6471265",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a frame with no defined index and a value that cannot be converted to a Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4373\u001b[0m, in \u001b[0;36mDataFrame._ensure_valid_index\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4373\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4374\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\series.py:512\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 512\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\construction.py:636\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    634\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 636\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\construction.py:695\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    697\u001b[0m     )\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (4799, 98) instead",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39316\\1958165135.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'true_labels'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outputs/test_set_predictions.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4090\u001b[0m             \u001b[1;31m# Column to set is duplicated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4091\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4092\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4093\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4094\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4300\u001b[0m         \u001b[0mSeries\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mTimeSeries\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconformed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDataFrames\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4301\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4302\u001b[0m         \"\"\"\n\u001b[1;32m-> 4303\u001b[1;33m         \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4305\u001b[0m         if (\n\u001b[0;32m   4306\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5028\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5029\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5030\u001b[0m         \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mExtensionArray\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moptional\u001b[0m \u001b[0mBlockValuesRefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5031\u001b[0m         \"\"\"\n\u001b[1;32m-> 5032\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5034\u001b[0m         \u001b[1;31m# Using a DataFrame would mean coercing values to one dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5035\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4371\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4372\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4373\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4375\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m   4376\u001b[0m                         \u001b[1;34m\"Cannot set a frame with no defined index \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4377\u001b[0m                         \u001b[1;34m\"and a value that cannot be converted to a Series\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m                     ) from err\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set a frame with no defined index and a value that cannot be converted to a Series"
     ]
    }
   ],
   "source": [
    "df['predictions'] = predictions\n",
    "df['true_labels'] = labels\n",
    "df.to_csv('outputs/test_set_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeac5fe-9010-47fb-b2bd-9dd91fa899bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(outputs.predictions, axis=2)\n",
    "\n",
    "predictions = predictions.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13dd6c-3e5a-4f75-85d9-6fbe7c73ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame()\n",
    "df_eval['predictions'] = predictions\n",
    "df_eval['true_labels'] = y\n",
    "df_eval.to_csv('outputs/test_set_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdb83d-b063-4bfb-b945-2dbcca2666cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def picklify(pickles,not_so_pickles):\n",
    "    '''\n",
    "    Saves a model or variable to a pickle file \n",
    "    '''\n",
    "    with open(pickles, 'wb') as p:\n",
    "        pickle.dump(not_so_pickles, p)\n",
    "picklify('basic_bert.pickle',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7847a2a-e4c6-46d5-bce8-6ecd8425b134",
   "metadata": {},
   "source": [
    "# Advanced Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eff570-aaa2-4309-8fdb-c849b6650259",
   "metadata": {},
   "source": [
    "### Replace -100 labels with 0 to ensure that the CRF can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cc842-33dc-4065-b5c3-8fbe01a7b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train,  df_test = pd.DataFrame(dataset_train), pd.DataFrame(dataset_test)\n",
    "df_test['labels'], df_train['labels'] = df_test['labels'].apply(lambda x: [e if e != -100 else 61 for e in x]), df_train['labels'].apply(lambda x: [e if e != -100 else 0 for e in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7ddd3-8fd8-478c-a7cc-09d0d0bcc492",
   "metadata": {},
   "source": [
    "## Create generator for training advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6df8f8-94b3-457e-85fb-7d0df9c70e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_generator(df, folder_path, chunk_size):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    chunk_start = 0\n",
    "    chunk_end = chunk_size\n",
    "    chunk_count = len(df) // chunk_size + (1 if len(df) % chunk_size else 0)\n",
    "    for i in range(chunk_count):\n",
    "        chunk = df[chunk_start:chunk_end]\n",
    "        file_name = f\"chunk_{i}.csv\"\n",
    "        chunk.to_csv(os.path.join(folder_path, file_name), index=False)\n",
    "        chunk_start += chunk_size\n",
    "        chunk_end += chunk_size\n",
    "\n",
    "create_generator(df_train, 'df_train_folder', chunk_size=50)\n",
    "create_generator(df_test, 'df_test_folder', chunk_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd00dda-bb05-442c-a0e2-7168452d4a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46641b-3d2a-4732-b96c-2ea93ede2f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['input_ids'].map(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2258a2a9-34fd-4479-a535-431e9149d4b8",
   "metadata": {},
   "source": [
    "#### ^Due to this length we will set our padding length max_len to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed1f52-5795-4ef5-976f-b3453779bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525978d5-a094-4731-8b67-89a7a04dcec7",
   "metadata": {},
   "source": [
    "## Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a7dbb-8113-4939-bd28-56d3a751c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "def data_generator(folder_path, epochs = 3, max_len=200):\n",
    "    def pad(tokens):\n",
    "        tokens = tokens.replace('[', '').replace(']', '')\n",
    "        tokens = tf.convert_to_tensor([int(token) for token in tokens.split(',')], dtype=tf.int32)\n",
    "        if tf.size(tokens) > max_len:\n",
    "            return tokens[tf.size(tokens)-max_len-1:]\n",
    "        else:\n",
    "            padding = tf.constant([0 for _ in range(max_len - tf.size(tokens))], dtype=tf.int32)\n",
    "            return tf.concat([tokens, padding], axis=0)\n",
    "    \n",
    "    def extend(attention):\n",
    "        attention = [int(x) for x in attention.replace('[', '').replace(']', '').split(',')]\n",
    "        return tf.convert_to_tensor(attention + [0] * (max_len - len(attention)), dtype=tf.int32)\n",
    "\n",
    "    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path)] * epochs\n",
    "    random.shuffle(file_paths)\n",
    "    for file_path in file_paths:\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # print(len(df))\n",
    "            for _, row in df.iterrows():\n",
    "                input_ids = pad(row['input_ids'])\n",
    "                attention_mask = extend(row['attention_mask'])\n",
    "                batch_x.append( tf.stack([input_ids, attention_mask], axis=1))\n",
    "                batch_y.append(pad(row['labels']))\n",
    "                # print( tf.stack([input_ids, attention_mask], axis=1))\n",
    "        yield tf.convert_to_tensor(batch_x), tf.convert_to_tensor(batch_y)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0495951-bdc7-4178-b569-b7d7583a432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [i for i in data_generator('df_test_folder')][0]\n",
    "input_dim = sample[0].shape\n",
    "num_labels = sample[1].shape[1]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee60711-7ef7-440b-882f-8b9804f3a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(set(label for sequence in df_train['labels'] for label in sequence))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336afed-d85b-419b-a52c-a1dd6fa2680c",
   "metadata": {},
   "source": [
    "## Advanced model loading and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c61d0-476a-424f-b80e-69365ef9e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional\n",
    "from tf2crf import CRF, ModelWithCRFLoss\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "def create_lstm_crf(seq_len, feature_dim, num_labels):\n",
    "    print(f'seq_len:{seq_len}, feature_dim:{feature_dim}, num_labels:{num_labels}')\n",
    "    input = Input(shape=(seq_len, feature_dim), dtype='float32')\n",
    "    \n",
    "    bilstm_layer1 = Bidirectional(LSTM(units=feature_dim, return_sequences=True))\n",
    "    bilstm_output1 = bilstm_layer1(input)\n",
    "    \n",
    "    bilstm_layer2 = Bidirectional(LSTM(units=num_labels, return_sequences=True))\n",
    "    bilstm_output2 = bilstm_layer2(bilstm_output1)\n",
    "    \n",
    "    crf = CRF(dtype='float32')\n",
    "    output = crf(bilstm_output2)\n",
    "    \n",
    "    base_model = Model(input, output)\n",
    "    model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "seq_len = sample[1].shape[1]\n",
    "feature_dim = sample[0].shape[2]\n",
    "num_labels = seq_len #label for every element in the sequence\n",
    "\n",
    "model = create_lstm_crf(seq_len, feature_dim, num_labels)\n",
    "model.build(input_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5d0ec-381d-4c06-acd5-8fbb0d9ef1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "loss = SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c04035-bf33-498d-9b28-a500eecce567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(0.001),loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa11603-c57f-4caf-83fa-9213e5364375",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input(\"type 'load' to load the model from checkpoint files and skip training, else press enter to start training\")  != 'load':\n",
    "    history = model.fit(data_generator('df_train_folder', epochs=epochs), batch_size=50, epochs=epochs, steps_per_epoch=809)#809\n",
    "    model.save_weights('./advanced_model2')\n",
    "else:\n",
    "    model.load_weights('./advanced_model2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359bff4-2c57-4ed1-9d74-686f51ef07ac",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60088c7-47a8-49a7-b2e7-613017d94cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_tensors = [i for i in data_generator('df_test_folder')]\n",
    "x_tensors, y_tensors = [i[0] for i in xy_tensors], [i[1] for i in xy_tensors]\n",
    "\n",
    "if len(x_tensors[-1]) != 50:\n",
    "    x_tensors.pop() \n",
    "    y_tensors.pop()\n",
    "\n",
    "x_tensors_filtered = [tensor for tensor in x_tensors if tensor.shape[0] == 50]\n",
    "y_tensors_filtered = [tensor for tensor in y_tensors if tensor.shape[0] == 50]\n",
    "\n",
    "x = tf.convert_to_tensor(x_tensors_filtered)\n",
    "y = tf.convert_to_tensor(y_tensors_filtered)\n",
    "x = tf.reshape(x, [-1, 200, 2])\n",
    "y = tf.reshape(y, [-1, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f52823-3f80-4ab9-88e6-c3e188bde15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(x[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d6ab0-242e-4972-962f-abab6b767cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf6b9e-a00e-4df8-9768-bcec7ad7afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760dc542-00a8-41ad-b73a-3df70ebe0879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
