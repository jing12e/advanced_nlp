{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925d7490-eceb-47ec-afd4-058185dd5907",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:02:57.628848300Z",
     "start_time": "2024-03-02T08:02:52.567609900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token can be pasted using 'Right-Click'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\katko\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, interpreter_login\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4185369c2aeddffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:09.167477300Z",
     "start_time": "2024-03-02T08:03:08.756115500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"token_classification_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e66291332607cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:19.819027300Z",
     "start_time": "2024-03-02T08:03:19.802028300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc992a4-f301-4e59-9ba4-fabca8814a4f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3acb54-8a43-45a3-8993-c784282d739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import extract_data_from_conll_extended\n",
    "extract_data_from_conll_extended(\"data/en_ewt-up-test.conllu\", \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f57dffa9a221e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:50.718490300Z",
     "start_time": "2024-03-02T08:03:49.564125200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eb9f2fdea94955af3089996d948e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89f397bbd9b42cbb17dd88ecfc8fd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['predicate', 'predicate_position', 'word', 'arguments'],\n",
       "        num_rows: 40482\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['predicate', 'predicate_position', 'word', 'arguments'],\n",
       "        num_rows: 4799\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "datasets = load_dataset('json', data_files={'train': 'train.json', 'test': 'test.json'})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca1314a051618b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:06.072630300Z",
     "start_time": "2024-03-02T08:04:06.055630900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicate': 'kill.01',\n",
       " 'predicate_position': 7,\n",
       " 'word': ['Al',\n",
       "  '-',\n",
       "  'Zaman',\n",
       "  ':',\n",
       "  'American',\n",
       "  'forces',\n",
       "  'killed',\n",
       "  'Shaikh',\n",
       "  'Abdullah',\n",
       "  'al',\n",
       "  '-',\n",
       "  'Ani',\n",
       "  ',',\n",
       "  'the',\n",
       "  'preacher',\n",
       "  'at',\n",
       "  'the',\n",
       "  'mosque',\n",
       "  'in',\n",
       "  'the',\n",
       "  'town',\n",
       "  'of',\n",
       "  'Qaim',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'Syrian',\n",
       "  'border',\n",
       "  '.'],\n",
       " 'arguments': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARG0',\n",
       "  'V',\n",
       "  'ARG1',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARGM-LOC',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6fae141fbc0385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:23.990387200Z",
     "start_time": "2024-03-02T08:04:23.975385900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a6b7ec65470697f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:29.769044100Z",
     "start_time": "2024-03-02T08:04:29.715044800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicate</th>\n",
       "      <th>predicate_position</th>\n",
       "      <th>word</th>\n",
       "      <th>arguments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know.01</td>\n",
       "      <td>2</td>\n",
       "      <td>[I, KNOW, YOU, HAVE, A, LOT, GOING, ON, WITH, YOU, AND, THE, LITTLE, WOMAN, .]</td>\n",
       "      <td>[ARG0, V, _, ARG1, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>provide.01</td>\n",
       "      <td>9</td>\n",
       "      <td>[Parties, ,, attached, is, the, promised, ruling, that, provides, procedural, guidance, for, the, hearings, on, 12/27, and, 12/28, .]</td>\n",
       "      <td>[_, _, _, _, _, _, ARG0, R-ARG0, V, _, ARG1, _, _, _, _, ARGM-TMP, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deworm.01</td>\n",
       "      <td>6</td>\n",
       "      <td>[They, made, need, medication, or, deworming, or, something, .]</td>\n",
       "      <td>[_, _, _, _, _, V, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>provide.01</td>\n",
       "      <td>47</td>\n",
       "      <td>[It, came, from, the, nation, whose, king, Enrique, VIII, adulterated, the, Bible, so, that, divorce, could, be, allowed, and, in, this, way, be, able, to, give, loose, rein, to, the, many, divorces, from, his, wives, and, subsequent, murdering, of, the, same, ones, and, to, whom, God, provided, a, wife, with, six, fingers, as, abomination, (, Anne, Boleyn, ), ..., once, again, 6, ,, number, of, the, Beast, ....]</td>\n",
       "      <td>[_, _, _, _, ARG2, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, R-ARG2, ARG0, V, _, ARG1, _, _, _, _, ARGM-PRD, _, C-ARG1, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>choose.01</td>\n",
       "      <td>24</td>\n",
       "      <td>[The, Sunburn, missile, ,, with, its, incredible, speed, and, ability, to, avoid, radar, detection, ,, would, do, terrible, damage, these, ships, if, Iran, chooses, to, retaliate, in, the, Gulf, after, an, American, attack, within, its, borders, .]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG0, V, _, ARG1, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hope.01</td>\n",
       "      <td>4</td>\n",
       "      <td>[But, let, s, hope, for, their, sake, (, and, the, sake, of, all, space, lovers, out, there, ), that, they, can, redefine, their, image, and, rekindle, the, hope, of, space, colonization, again, .]</td>\n",
       "      <td>[_, _, ARG0, V, _, _, ARGM-PRP, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG1, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>be.01</td>\n",
       "      <td>48</td>\n",
       "      <td>[The, best, option, ,, now, ,, under, the, present, difficult, circumstances, is, for, Colombo, to, do, its, own, dirty, work, ,, although, New, Delhi, can, always, be, counted, on, to, render, good, neighborly, help, because, of, the, shared, belief, that, religion, ,, ethnicity, and, language, can, not, be, the, basis, for, secession, .]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG1, _, _, _, _, ARGM-MOD, ARGM-NEG, V, _, ARG2, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>control.01</td>\n",
       "      <td>52</td>\n",
       "      <td>[Goal, is, to, (, politely, ?, ), refute, Loretta, Lynch, 's, and, Carl, Woods, ', continued, assertions, that, 1, ), California, 's, move, to, deregulate, was, based, solely, on, ideology, with, no, basis, in, fact, and, 2, ), the, solution, is, to, turn, back, the, clock, to, command, -, and, -, control, regulation, .]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>house.01</td>\n",
       "      <td>12</td>\n",
       "      <td>[What, will, the, federal, government, do, to, prevent, inflation, in, the, housing, and, building, market, ?]</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, V, _, _, _, _]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>recommend.01</td>\n",
       "      <td>4</td>\n",
       "      <td>[I, will, never, recommend, this, gym, to, any, woman, .]</td>\n",
       "      <td>[ARG0, ARGM-MOD, ARGM-NEG, V, _, ARG1, _, _, ARG2, _]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4a00a-883c-4620-b88d-fc3345d33e2d",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "237f4338dcca93b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:22.530273900Z",
     "start_time": "2024-03-02T09:09:22.181391900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2996c7fe621ae6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:23.431553200Z",
     "start_time": "2024-03-02T09:09:23.411302100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dcb547f-f53b-4583-a502-21a4b762b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(tokenized_input, labels):\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "    aligned_labels = ['_'] * len(word_ids) \n",
    "    label_index = 0 \n",
    "    for i, word_id in enumerate(word_ids):\n",
    "        try:\n",
    "            if word_id is None:\n",
    "                aligned_labels[i] = '[PAD]'\n",
    "                continue \n",
    "            original_label = labels[word_id]\n",
    "            if original_label == '_':\n",
    "                continue \n",
    "            if i == 0 or word_id != word_ids[i-1]:\n",
    "                prefix = ''\n",
    "            else:\n",
    "                prefix = ''\n",
    "            aligned_labels[i] = f'{prefix}{original_label}'\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4858eeaa61a663d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:24.745351400Z",
     "start_time": "2024-03-02T09:09:24.731350300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(instance):\n",
    "    def align(tokenized_input, labels):\n",
    "        word_ids = tokenized_input.word_ids()\n",
    "        aligned_labels = ['_'] * len(word_ids) \n",
    "        label_index = 0 \n",
    "        for i, word_id in enumerate(word_ids):\n",
    "            try:\n",
    "                if word_id is None:\n",
    "                    aligned_labels[i] = '[PAD]'\n",
    "                    continue \n",
    "                original_label = labels[word_id]\n",
    "                if original_label == '_':\n",
    "                    continue \n",
    "                if i == 0 or word_id != word_ids[i-1]:\n",
    "                    prefix = ''\n",
    "                else:\n",
    "                    prefix = ''\n",
    "                aligned_labels[i] = f'{prefix}{original_label}'\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        return aligned_labels\n",
    "    sentence = instance[\"word\"]\n",
    "    labels = instance[\"arguments\"]\n",
    "    tokenized_input = tokenizer(sentence, is_split_into_words=True)\n",
    "    predicate = instance['predicate']\n",
    "    predicate = tokenizer(predicate)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "    aligned_labels = align(tokenized_input, labels)\n",
    "    tokenized_input['input_ids'].extend(predicate['input_ids'][1:]), tokenized_input['attention_mask'].extend(predicate['attention_mask'][1:]), aligned_labels.extend(['[PAD]' for i in range(len(predicate['input_ids'][1:]))])\n",
    "    tokenized_input['labels'] = aligned_labels\n",
    "    \n",
    "    return tokenized_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92718ab9-217a-4d7a-b9c8-b91613a25c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40482\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets['train']))\n",
    "training_set = [tokenize(instance) for instance in datasets['train']]\n",
    "test_set = [tokenize(instance) for instance in datasets['test']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5e57dd6-e735-48a0-a182-37051b60fe9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102, 3102, 1012, 5890, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': ['[PAD]', '_', '_', '_', '_', '_', '_', 'ARG0', 'V', 'ARG1', 'ARG1', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'ARGM-LOC', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']}\n"
     ]
    }
   ],
   "source": [
    "sample = training_set[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "287db1bd-6289-4b69-a9d4-1747102c5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Features, Sequence, Value\n",
    "\n",
    "features = Features({\n",
    "    \"input_ids\": Sequence(feature=Value(dtype='int64')),\n",
    "    \"attention_mask\": Sequence(feature=Value(dtype='int64')),\n",
    "    \"labels\": Sequence(feature=Value(dtype='int64')),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77e11cd7-3183-4cc0-8fe6-bbff43de4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen = ['R-ARGM-ADJ', '_', 'ARGM-ADJ']\n",
    "label_list = list(set(label for instance in training_set for label in instance['labels'] + unseen))\n",
    "label_dict = {label:int(i) for i, label in enumerate(list(label_list))}\n",
    "# label_dict['[PAD]'] = -100\n",
    "for instance in training_set:\n",
    "    instance['labels'] = [int(label_dict[label]) for label in instance['labels']]\n",
    "for instance in test_set:\n",
    "    instance['labels'] = [int(label_dict[label]) for label in instance['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7f3c443-2b4c-4c1c-8201-69468605b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_dict({\"input_ids\": [item['input_ids'] for item in training_set],\n",
    "                             \"attention_mask\": [item['attention_mask'] for item in training_set],\n",
    "                             \"labels\": [item['labels'] for item in training_set]}, features=features)\n",
    "\n",
    "dataset_test = Dataset.from_dict({\"input_ids\": [item['input_ids'] for item in test_set],\n",
    "                             \"attention_mask\": [item['attention_mask'] for item in test_set],\n",
    "                             \"labels\": [item['labels'] for item in test_set]}, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e12cd73680f6939f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "# model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b358ca3f-63b2-4df9-83da-c7ca2964c75e",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d5094dc-1fb6-4706-8451-0c03449c7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68f52781-dbe4-4c67-bda0-5b641950faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27138d5c-1d91-4084-8675-b1f949b18e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katko\\AppData\\Local\\Temp\\ipykernel_30772\\2951164050.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2b9e9f9-0c5c-48b8-98c1-eaf836b71064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-DIS seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-REC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-MOD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-ADJ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG1-DSP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGA seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-TMP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG4 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-EXT seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-ADV seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-GOL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-PRP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-LVB seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-MNR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-PRR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-CAU seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARGM-CXN seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-NEG seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-COM seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-DIR seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARGM-PRD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARGM-LOC seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: ARG5 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: R-ARG0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: _ seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-ARG1-DSP seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: C-V seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADJ': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ADV': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARG0': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG1': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG1-DSP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARG2': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG3': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARG4': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-ADJ': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-ADV': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-CAU': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-COM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-CXN': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-DIR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-EXT': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-GOL': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-LOC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-MNR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ARGM-PRP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-PRR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'ARGM-TMP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'CAU': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'COM': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'CXN': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'DIR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'DIS': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'DSP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'EXT': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'GOL': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'LOC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'LVB': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'MNR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'MOD': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'NEG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PAD]': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PRD': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PRP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PRR': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'REC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG0': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG1': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG2': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG3': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG4': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RG5': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'RGA': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'TMP': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'V': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " '_': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(label_list)\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e7af19e-b45d-4a9a-a650-1c0d8afee453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb16b28-bddf-4545-ac99-010ea003d435",
   "metadata": {},
   "source": [
    "## Training the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6ca14-aed3-41cd-b002-a0d71a09972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_model(pickles):\n",
    "    '''\n",
    "    Input: string name with .pickle extension. Must be present in working directory. Check with 'pwd' command\n",
    "    Loads pretrained model variable from pickle file at filepath(pickle).\n",
    "    '''\n",
    "    with open(pickles, 'rb') as p:\n",
    "        return pickle.load(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d4767-b92e-4015-aa4f-0d5144b81311",
   "metadata": {},
   "source": [
    "### Current version = opt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fac29-8efb-44dc-b30d-fe835f003289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, DistilBertForTokenClassification\n",
    "if input(\"Type 'load' to load a model from the directory, else press enter\") == 'load':\n",
    "    # basic_model = load_model('basic_bert.pickle')\n",
    "    opt = input(\"Type 1 to load from Jing's repo, type 2 to load from Demothi's repo\")\n",
    "    if opt == '1':\n",
    "        basic_model = DistilBertForTokenClassification.from_pretrained(\"Jing1113/distilbert-base-uncased-finetuned-srl\")\n",
    "    elif opt == '2':\n",
    "        basic_model = DistilBertForTokenClassification.from_pretrained(\"somskat/distilbert-base-uncased-finetuned-ner\")\n",
    "\n",
    "else:\n",
    "    basic_model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17c6d4-ca25-48cd-94fe-2fe9496e9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    basic_model,\n",
    "    args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce2d7de-5e13-4521-b519-56392cb81c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if input(\"type 'y' to train model, press enter to skip\") == 'y':\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f83ee8-6e2e-4506-91bf-77293f950e57",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef0311-7415-4a16-a8c8-f94e160fac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x, y = dataset_test.select_columns(['input_ids','attention_mask']), dataset_test.select_columns(['labels'])\n",
    "# basic_model.eval()\n",
    "# with torch.no_grad():\n",
    "predictions, labels, _ = trainer.predict(x)\n",
    "# predictions = np.argmax(predictions, axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49b21d-1404-4e90-9934-6cc9e82b2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, _ = trainer.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19306e48-f0ba-4df8-aeff-fd418f463e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4eedad-ab87-43a8-a627-c91e995741d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bff258-8894-47f0-864e-f4cd68c1de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfcc10-93ad-4bd2-935c-080688cedfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_predictions = [pred for sublist in predictions for pred in sublist]\n",
    "flat_labels = [label for sublist in labels for label in sublist]\n",
    "\n",
    "#Now create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'predictions': flat_predictions,\n",
    "    'true_labels': flat_labels\n",
    "})\n",
    "\n",
    "df.to_csv('test_set_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2500a6-3957-4664-aa37-5ca5408fd765",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd2a7d-94e1-4894-9ef5-a500b4ba40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdb83d-b063-4bfb-b945-2dbcca2666cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def picklify(pickles,not_so_pickles):\n",
    "    '''\n",
    "    Saves a model or variable to a pickle file \n",
    "    '''\n",
    "    with open(pickles, 'wb') as p:\n",
    "        pickle.dump(not_so_pickles, p)\n",
    "if input(\"Save to pickle file?(y/n)\") == 'y': \n",
    "    picklify('basic_bert.pickle',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7847a2a-e4c6-46d5-bce8-6ecd8425b134",
   "metadata": {},
   "source": [
    "# Advanced Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eff570-aaa2-4309-8fdb-c849b6650259",
   "metadata": {},
   "source": [
    "### Replace -100 labels with 0 to ensure that the CRF can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "618cc842-33dc-4065-b5c3-8fbe01a7b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train,  df_test = pd.DataFrame(dataset_train), pd.DataFrame(dataset_test)\n",
    "df_test['labels'], df_train['labels'] = df_test['labels'].apply(lambda x: [e if e != -100 else 61 for e in x]), df_train['labels'].apply(lambda x: [e if e != -100 else 0 for e in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b7ddd3-8fd8-478c-a7cc-09d0d0bcc492",
   "metadata": {},
   "source": [
    "## Create generator for training advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4ef9bea-5fb6-45ab-8b4a-b84a65f35a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 2632, 1011, 23564, 2386, 1024, 2137, 274...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 48, 13, 3, 3, 59,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 13, 59, 59, 59, 3, 59, 59, 59, 59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 13, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 48, 59, 59, 59, 59, 10, 59, 13, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 3, 10, 50, 13, 18, 8, 59, 59, 59, 59, 59,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 13, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40479</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 48, 59, 59, 59, 59, 59, 59, 59, 8, 37, 59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40480</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40481</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40482 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          attention_mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "40477  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40478  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40479  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40480  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40481  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                               input_ids  \\\n",
       "0      [101, 2632, 1011, 23564, 2386, 1024, 2137, 274...   \n",
       "1      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "2      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "3      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "4      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "...                                                  ...   \n",
       "40477  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40478  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40479  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40480  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40481  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "\n",
       "                                                  labels  \n",
       "0      [40, 59, 59, 59, 59, 59, 59, 48, 13, 3, 3, 59,...  \n",
       "1      [40, 59, 59, 13, 59, 59, 59, 3, 59, 59, 59, 59...  \n",
       "2      [40, 59, 59, 59, 59, 59, 59, 59, 59, 13, 59, 5...  \n",
       "3      [40, 59, 59, 48, 59, 59, 59, 59, 10, 59, 13, 2...  \n",
       "4      [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...  \n",
       "...                                                  ...  \n",
       "40477  [40, 3, 10, 50, 13, 18, 8, 59, 59, 59, 59, 59,...  \n",
       "40478  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 13, 5...  \n",
       "40479  [40, 48, 59, 59, 59, 59, 59, 59, 59, 8, 37, 59...  \n",
       "40480  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...  \n",
       "40481  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...  \n",
       "\n",
       "[40482 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_train, advanced_test = pd.DataFrame(training_set), pd.DataFrame(test_set)\n",
    "advanced_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4bac7834-04e3-40f5-b44c-5b4615bf8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_predicate(tokens, labels):\n",
    "    split = tokens.index(102)\n",
    "    return tokens[:split], tokens[split+1:-1], labels[:split],\n",
    "\n",
    "a,b,c = find_predicate(advanced_train.at[1,'input_ids'],advanced_train.at[1,'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b02b1dbe-d3dc-4591-a89f-d2d57c5f2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_train['predicate'] = advanced_train['input_ids']\n",
    "advanced_test['predicate'] = advanced_test['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8baa9198-9ef7-4fdc-b26e-f88bb1bb34dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 2632, 1011, 23564, 2386, 1024, 2137, 274...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 48, 13, 3, 3, 59,...</td>\n",
       "      <td>[101, 2632, 1011, 23564, 2386, 1024, 2137, 274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 13, 59, 59, 59, 3, 59, 59, 59, 59...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 13, 59, 5...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 48, 59, 59, 59, 59, 10, 59, 13, 2...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 3, 10, 50, 13, 18, 8, 59, 59, 59, 59, 59,...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 13, 5...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40479</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 48, 59, 59, 59, 59, 59, 59, 59, 8, 37, 59...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40480</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40481</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40482 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          attention_mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "40477  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40478  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40479  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40480  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40481  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                               input_ids  \\\n",
       "0      [101, 2632, 1011, 23564, 2386, 1024, 2137, 274...   \n",
       "1      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "2      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "3      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "4      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "...                                                  ...   \n",
       "40477  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40478  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40479  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40480  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40481  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "\n",
       "                                                  labels  \\\n",
       "0      [40, 59, 59, 59, 59, 59, 59, 48, 13, 3, 3, 59,...   \n",
       "1      [40, 59, 59, 13, 59, 59, 59, 3, 59, 59, 59, 59...   \n",
       "2      [40, 59, 59, 59, 59, 59, 59, 59, 59, 13, 59, 5...   \n",
       "3      [40, 59, 59, 48, 59, 59, 59, 59, 10, 59, 13, 2...   \n",
       "4      [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...   \n",
       "...                                                  ...   \n",
       "40477  [40, 3, 10, 50, 13, 18, 8, 59, 59, 59, 59, 59,...   \n",
       "40478  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 13, 5...   \n",
       "40479  [40, 48, 59, 59, 59, 59, 59, 59, 59, 8, 37, 59...   \n",
       "40480  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...   \n",
       "40481  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...   \n",
       "\n",
       "                                               predicate  \n",
       "0      [101, 2632, 1011, 23564, 2386, 1024, 2137, 274...  \n",
       "1      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...  \n",
       "2      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...  \n",
       "3      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...  \n",
       "4      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...  \n",
       "...                                                  ...  \n",
       "40477  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...  \n",
       "40478  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...  \n",
       "40479  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...  \n",
       "40480  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...  \n",
       "40481  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...  \n",
       "\n",
       "[40482 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53a9cb6b-80ea-42fc-be70-2935e8296384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_predicate(pred):\n",
    "    if len(pred) > 1:\n",
    "        return pred[:2]\n",
    "    elif len(pred) == 2:\n",
    "        return pred.append(0)\n",
    "    \n",
    "for i,r in advanced_train.iterrows():\n",
    "    advanced_train.at[i,'input_ids'], advanced_train.at[i,'predicate'], advanced_train.at[i,'labels']= find_predicate(r['input_ids'],r['labels'])\n",
    "\n",
    "for i,r in advanced_test.iterrows():\n",
    "    advanced_test.at[i,'input_ids'], advanced_test.at[i,'predicate'], advanced_test.at[i,'labels'] = find_predicate(r['input_ids'],r['labels'])\n",
    "advanced_train['predicate'] = advanced_train['predicate'].apply(handle_predicate)\n",
    "advanced_test['predicate'] = advanced_test['predicate'].apply(handle_predicate)\n",
    "\n",
    "\n",
    "# advanced_train['labels'] = pd.Series([[int(label_dict[label]) for label in arg] for arg in advanced_train['labels']])\n",
    "\n",
    "# advanced_test['labels'] = pd.Series([[int(label_dict[label]) for label in arg] for arg in advanced_test['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2e85ab1-aa37-4e7b-af51-8615e4987386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 2632, 1011, 23564, 2386, 1024, 2137, 274...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 48, 13, 3, 3, 59,...</td>\n",
       "      <td>[3102, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 13, 59, 59, 59, 3, 59, 59, 59, 59...</td>\n",
       "      <td>[3102, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 13, 59, 5...</td>\n",
       "      <td>[2022, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 48, 59, 59, 59, 59, 10, 59, 13, 2...</td>\n",
       "      <td>[3426, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "      <td>[2272, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 3, 10, 50, 13, 18, 8, 59, 59, 59, 59, 59,...</td>\n",
       "      <td>[2709, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 13, 5...</td>\n",
       "      <td>[2031, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40479</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 48, 59, 59, 59, 59, 59, 59, 59, 8, 37, 59...</td>\n",
       "      <td>[4797, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40480</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "      <td>[2147, 1012]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40481</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...</td>\n",
       "      <td>[40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...</td>\n",
       "      <td>[4685, 1012]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40482 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          attention_mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "40477  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40478  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40479  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40480  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "40481  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                               input_ids  \\\n",
       "0      [101, 2632, 1011, 23564, 2386, 1024, 2137, 274...   \n",
       "1      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "2      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "3      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "4      [101, 1031, 2023, 4288, 1997, 1037, 9768, 2930...   \n",
       "...                                                  ...   \n",
       "40477  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40478  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40479  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40480  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "40481  [101, 1045, 2097, 2196, 2709, 2045, 2153, 1006...   \n",
       "\n",
       "                                                  labels     predicate  \n",
       "0      [40, 59, 59, 59, 59, 59, 59, 48, 13, 3, 3, 59,...  [3102, 1012]  \n",
       "1      [40, 59, 59, 13, 59, 59, 59, 3, 59, 59, 59, 59...  [3102, 1012]  \n",
       "2      [40, 59, 59, 59, 59, 59, 59, 59, 59, 13, 59, 5...  [2022, 1012]  \n",
       "3      [40, 59, 59, 48, 59, 59, 59, 59, 10, 59, 13, 2...  [3426, 1012]  \n",
       "4      [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...  [2272, 1012]  \n",
       "...                                                  ...           ...  \n",
       "40477  [40, 3, 10, 50, 13, 18, 8, 59, 59, 59, 59, 59,...  [2709, 1012]  \n",
       "40478  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 13, 5...  [2031, 1012]  \n",
       "40479  [40, 48, 59, 59, 59, 59, 59, 59, 59, 8, 37, 59...  [4797, 1012]  \n",
       "40480  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...  [2147, 1012]  \n",
       "40481  [40, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 5...  [4685, 1012]  \n",
       "\n",
       "[40482 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2b1b6c0-caa4-4484-9c98-3cb7e5585d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(words, predicate, arg, n=5):\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - n + 1):\n",
    "        ngram = words[i:i+n]\n",
    "        ngram_label = arg[i:i+n]\n",
    "        ngrams.append({'predicate': predicate,\n",
    "                       'input_ids': ngram,\n",
    "                       'labels': ngram_label})\n",
    "    return ngrams\n",
    "\n",
    "ngram_data = []\n",
    "for index, row in advanced_test.iterrows():\n",
    "    ngram_data.extend(generate_ngrams(row['input_ids'], row['predicate'], row['labels']))\n",
    "\n",
    "ngram_test = pd.DataFrame(ngram_data)\n",
    "\n",
    "ngram_data = []\n",
    "for index, row in advanced_train.iterrows():\n",
    "    ngram_data.extend(generate_ngrams(row['input_ids'], row['predicate'], row['labels']))\n",
    "\n",
    "ngram_train = pd.DataFrame(ngram_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dc3a68aa-2294-47ff-bacd-e1c5a8c1e2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicate</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[22822, 8458]</td>\n",
       "      <td>[101, 2054, 2065, 8224, 22822]</td>\n",
       "      <td>[40, 59, 59, 3, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[22822, 8458]</td>\n",
       "      <td>[2054, 2065, 8224, 22822, 8458]</td>\n",
       "      <td>[59, 59, 3, 13, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[22822, 8458]</td>\n",
       "      <td>[2065, 8224, 22822, 8458, 2098]</td>\n",
       "      <td>[59, 3, 13, 13, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[22822, 8458]</td>\n",
       "      <td>[8224, 22822, 8458, 2098, 2046]</td>\n",
       "      <td>[3, 13, 13, 13, 59]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[22822, 8458]</td>\n",
       "      <td>[22822, 8458, 2098, 2046, 8224]</td>\n",
       "      <td>[13, 13, 13, 59, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97567</th>\n",
       "      <td>[2224, 1012]</td>\n",
       "      <td>[1996, 3563, 3314, 1998, 9104]</td>\n",
       "      <td>[59, 59, 59, 59, 59]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97568</th>\n",
       "      <td>[2224, 1012]</td>\n",
       "      <td>[3563, 3314, 1998, 9104, 11110]</td>\n",
       "      <td>[59, 59, 59, 59, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97569</th>\n",
       "      <td>[2224, 1012]</td>\n",
       "      <td>[3314, 1998, 9104, 11110, 2000]</td>\n",
       "      <td>[59, 59, 59, 3, 59]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97570</th>\n",
       "      <td>[2224, 1012]</td>\n",
       "      <td>[1998, 9104, 11110, 2000, 2224]</td>\n",
       "      <td>[59, 59, 3, 59, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97571</th>\n",
       "      <td>[2224, 1012]</td>\n",
       "      <td>[9104, 11110, 2000, 2224, 1012]</td>\n",
       "      <td>[59, 3, 59, 13, 59]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           predicate                        input_ids                labels\n",
       "0      [22822, 8458]   [101, 2054, 2065, 8224, 22822]   [40, 59, 59, 3, 13]\n",
       "1      [22822, 8458]  [2054, 2065, 8224, 22822, 8458]   [59, 59, 3, 13, 13]\n",
       "2      [22822, 8458]  [2065, 8224, 22822, 8458, 2098]   [59, 3, 13, 13, 13]\n",
       "3      [22822, 8458]  [8224, 22822, 8458, 2098, 2046]   [3, 13, 13, 13, 59]\n",
       "4      [22822, 8458]  [22822, 8458, 2098, 2046, 8224]   [13, 13, 13, 59, 0]\n",
       "...              ...                              ...                   ...\n",
       "97567   [2224, 1012]   [1996, 3563, 3314, 1998, 9104]  [59, 59, 59, 59, 59]\n",
       "97568   [2224, 1012]  [3563, 3314, 1998, 9104, 11110]   [59, 59, 59, 59, 3]\n",
       "97569   [2224, 1012]  [3314, 1998, 9104, 11110, 2000]   [59, 59, 59, 3, 59]\n",
       "97570   [2224, 1012]  [1998, 9104, 11110, 2000, 2224]   [59, 59, 3, 59, 13]\n",
       "97571   [2224, 1012]  [9104, 11110, 2000, 2224, 1012]   [59, 3, 59, 13, 59]\n",
       "\n",
       "[97572 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "799fd06d-49dd-4b6b-878d-b69c9f6b9301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_generator(df, folder_path, chunk_size):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    chunk_start = 0\n",
    "    chunk_end = chunk_size\n",
    "    chunk_count = len(df) // chunk_size + (1 if len(df) % chunk_size else 0)\n",
    "    for i in range(chunk_count):\n",
    "        chunk = df[chunk_start:chunk_end]\n",
    "        file_name = f\"chunk_{i}.csv\"\n",
    "        chunk.to_csv(os.path.join(folder_path, file_name), index=False)\n",
    "        chunk_start += chunk_size\n",
    "        chunk_end += chunk_size\n",
    "\n",
    "create_generator(ngram_train, 'df_train_folder', chunk_size=50)#df_train, df_test\n",
    "create_generator(ngram_test, 'df_test_folder', chunk_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525978d5-a094-4731-8b67-89a7a04dcec7",
   "metadata": {},
   "source": [
    "## Loading & final preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c0a7dbb-8113-4939-bd28-56d3a751c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "def data_generator(folder_path, epochs = 3, max_len=200):\n",
    "    def pad(tokens):\n",
    "        tokens = tokens.replace('[', '').replace(']', '')\n",
    "        tokens = tf.convert_to_tensor([int(token) for token in tokens.split(',')], dtype=tf.int32)\n",
    "        if tf.size(tokens) > max_len:\n",
    "            return tokens[tf.size(tokens)-max_len-1:]\n",
    "        else:\n",
    "            padding = tf.constant([0 for _ in range(max_len - tf.size(tokens))], dtype=tf.int32)\n",
    "            return tf.concat([tokens, padding], axis=0)\n",
    "    \n",
    "    def extend(attention):\n",
    "        attention = [int(x) for x in attention.replace('[', '').replace(']', '').split(',')]\n",
    "        return tf.convert_to_tensor(attention + [0] * (max_len - len(attention)), dtype=tf.int32)\n",
    "\n",
    "    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path)] * epochs\n",
    "    random.shuffle(file_paths)\n",
    "    for file_path in file_paths:\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # print(len(df))\n",
    "            for _, row in df.iterrows():\n",
    "                input_ids = pad(row['input_ids'])\n",
    "                attention_mask = extend(row['attention_mask'])\n",
    "                batch_x.append( tf.stack([input_ids, attention_mask], axis=1))\n",
    "                batch_y.append(pad(row['labels']))\n",
    "                # print( tf.stack([input_ids, attention_mask], axis=1))\n",
    "        yield tf.convert_to_tensor(batch_x), tf.convert_to_tensor(batch_y)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a480afb9-af8d-4816-81e3-b4364a20145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def data_generator2(folder_path, epochs = 3):\n",
    "    def tensorify(string):\n",
    "        string = string.replace('[', '').replace(']', '')\n",
    "        return [int(tok) for tok in string.split(',')]\n",
    "        \n",
    "    def normalize_array(array, min_range=0, max_range=1, maxv=29556 ):\n",
    "        array = np.array(array)\n",
    "        minv = 0\n",
    "        array = (array - minv) / (maxv - minv) * (max_range - min_range) + min_range\n",
    "        return array\n",
    "    \n",
    "    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path)] * epochs\n",
    "    random.shuffle(file_paths)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        i=  0\n",
    "        with open(file_path, 'r') as f:\n",
    "            df = pd.read_csv(file_path)\n",
    "            for _, row in df.iterrows():\n",
    "                input_ids = tensorify(row['input_ids'])\n",
    "                predicate = tensorify(row['predicate'])\n",
    "                window = []\n",
    "                for input_id in input_ids:\n",
    "                    \n",
    "                    window.append(tf.constant([input_id, predicate[0], predicate[1]])) \n",
    "                if len(window) == 5:\n",
    "                    batch_x.append(tf.convert_to_tensor(window))\n",
    "                    batch_y.append(tensorify(row['labels']))\n",
    "        if batch_x and batch_y:\n",
    "            yield tf.convert_to_tensor(normalize_array(batch_x),dtype='float32'), tf.convert_to_tensor(batch_y,dtype='int32')\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c0495951-bdc7-4178-b569-b7d7583a432f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30772\\1262673804.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_generator2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'df_test_folder'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30772\\1262673804.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_generator2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'df_test_folder'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30772\\3139452370.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(folder_path, epochs)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0minput_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                     \u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                     \u001b[0mbatch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                     \u001b[0mbatch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensorify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_x\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[1;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mno\u001b[0m \u001b[0mconversion\u001b[0m \u001b[0mfunction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mregistered\u001b[0m \u001b[1;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0ma\u001b[0m \u001b[0mregistered\u001b[0m \u001b[0mconversion\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m   \"\"\"\n\u001b[1;32m--> 161\u001b[1;33m   return convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m    162\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m   )\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m ) -> tensor_lib.Tensor:\n\u001b[0;32m    169\u001b[0m   \u001b[1;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m   \u001b[1;31m# preferred_dtype = preferred_dtype or dtype_hint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m   return tensor_conversion_registry.convert(\n\u001b[0m\u001b[0;32m    172\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m   )\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    230\u001b[0m                   \u001b[1;34mf\"actual = {ret.dtype.base_dtype.name}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                   name=name))\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1581\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1585\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"packed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[0;32m   1488\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1489\u001b[0m     \u001b[1;31m# NOTE: Fast path when all the items are tensors, this doesn't do any type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1490\u001b[0m     \u001b[1;31m# checking.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_or_tuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1492\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_or_tuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1493\u001b[0m   \u001b[0mmust_pack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1494\u001b[0m   \u001b[0mconverted_elems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   6716\u001b[0m         _ctx, \"Pack\", name, values, \"axis\", axis)\n\u001b[0;32m   6717\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6718\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6719\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6720\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6721\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6722\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6723\u001b[0m       return pack_eager_fallback(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sample = [i for i in data_generator2('df_test_folder',epochs=1)][0]\n",
    "input_dim = sample[0].shape\n",
    "num_labels = sample[1].shape[1]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a641d-1e2a-403b-8a23-079c94e7bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = sample[0].shape\n",
    "num_labels = sample[1].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cf616-8615-408e-8b22-55ff31c5dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb591a21-4a4c-43c1-99ad-573693976d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac24fb-3a88-4eb8-aa70-0c74be565186",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('df_test_folder/chunk_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce83d1b-8d15-49af-9dfd-90d2801c941d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5ee60711-7ef7-440b-882f-8b9804f3a4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(set(label for sequence in df_train['labels'] for label in sequence))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336afed-d85b-419b-a52c-a1dd6fa2680c",
   "metadata": {},
   "source": [
    "## Advanced model loading and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "370c61d0-476a-424f-b80e-69365ef9e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len:5, feature_dim:3, num_labels:5\n",
      "Model: \"model_with_crf_loss_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model_22 (Functional)       ((None, 5),               4919      \n",
      "                              (None, 5, 62),                     \n",
      "                              (None,),                           \n",
      "                              (62, 62))                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4923 (34.25 KB)\n",
      "Trainable params: 4919 (34.23 KB)\n",
      "Non-trainable params: 4 (16.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, TimeDistributed\n",
    "from tf2crf import CRF, ModelWithCRFLoss\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "def create_lstm_crf(seq_len, feature_dim, num_labels):\n",
    "    print(f'seq_len:{seq_len}, feature_dim:{feature_dim}, num_labels:{num_labels}')\n",
    "    input = Input(shape=(seq_len, feature_dim), dtype='float64')\n",
    "    \n",
    "    bilstm_layer1 = Bidirectional(LSTM(units=feature_dim, return_sequences=True))\n",
    "    bilstm_output1 = bilstm_layer1(input)\n",
    "    \n",
    "    bilstm_layer2 = Bidirectional(LSTM(units=num_labels, return_sequences=True))\n",
    "    bilstm_output2 = bilstm_layer2(bilstm_output1)\n",
    "\n",
    "    dense = TimeDistributed(Dense(num_labels, activation='relu'))#(bilstm_output2)\n",
    "    outputs = dense(bilstm_output2)\n",
    "    \n",
    "    crf = CRF(int(62), dtype='float64')\n",
    "    output = crf(outputs)\n",
    "    \n",
    "    base_model = Model(input, output)\n",
    "    model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "seq_len = sample[1].shape[1]\n",
    "feature_dim = sample[0].shape[2]\n",
    "num_labels = seq_len #label for every element in the sequence\n",
    "\n",
    "model = create_lstm_crf(seq_len, feature_dim, num_labels)\n",
    "model.build((None, int(seq_len), int(feature_dim)))#model.build(input_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "46d5d0ec-381d-4c06-acd5-8fbb0d9ef1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "loss = SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "62c04035-bf33-498d-9b28-a500eecce567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(0.001))#,loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "3aa11603-c57f-4caf-83fa-9213e5364375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "type 'load' to load the model from checkpoint files and skip training, else press enter to start training \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 703s 34ms/step - loss: 3.1094 - accuracy: 0.8745\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 698s 35ms/step - loss: 2.8249 - accuracy: 0.8813\n",
      "Epoch 3/3\n",
      "19747/20000 [============================>.] - ETA: 8s - loss: 2.6916 - accuracy: 0.8842"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nNameError: name 'mx' is not defined\nTraceback (most recent call last):\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\katko\\AppData\\Local\\Temp\\ipykernel_30772\\925479162.py\", line 36, in data_generator2\n    print('mx',mx,'mxl',mxl)\n               ^^\n\nNameError: name 'mx' is not defined\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_28764872]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[270], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load the model from checkpoint files and skip training, else press enter to start training\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_generator2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_train_folder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#809\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./advanced_model4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nNameError: name 'mx' is not defined\nTraceback (most recent call last):\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 270, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\katko\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py\", line 917, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\katko\\AppData\\Local\\Temp\\ipykernel_30772\\925479162.py\", line 36, in data_generator2\n    print('mx',mx,'mxl',mxl)\n               ^^\n\nNameError: name 'mx' is not defined\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_28764872]"
     ]
    }
   ],
   "source": [
    "if input(\"type 'load' to load the model from checkpoint files and skip training, else press enter to start training\")  != 'load':\n",
    "    model.fit(data_generator2('df_train_folder', epochs=int(epochs)), batch_size=int(50), epochs=int(epochs), steps_per_epoch=int(20000))#809\n",
    "    model.save_weights('./advanced_model4')\n",
    "else:\n",
    "    model.load_weights('./advanced_model4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359bff4-2c57-4ed1-9d74-686f51ef07ac",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60088c7-47a8-49a7-b2e7-613017d94cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_tensors = [i for i in data_generator2('df_test_folder')]\n",
    "x_tensors, y_tensors = [i[0] for i in xy_tensors], [i[1] for i in xy_tensors]\n",
    "\n",
    "if len(x_tensors[-1]) != 50:\n",
    "    x_tensors.pop() \n",
    "    y_tensors.pop()\n",
    "\n",
    "x_tensors_filtered = [tensor for tensor in x_tensors if tensor.shape[0] == 50]\n",
    "y_tensors_filtered = [tensor for tensor in y_tensors if tensor.shape[0] == 50]\n",
    "\n",
    "x = tf.convert_to_tensor(x_tensors_filtered)\n",
    "y = tf.convert_to_tensor(y_tensors_filtered)\n",
    "x = tf.reshape(x, [-1, 200, 2])\n",
    "y = tf.reshape(y, [-1, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e66964-cc1f-4144-8316-d75c4993c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(x, [-1, 5, 3])\n",
    "y = tf.reshape(y, [-1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f52823-3f80-4ab9-88e6-c3e188bde15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(x[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d6ab0-242e-4972-962f-abab6b767cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf6b9e-a00e-4df8-9768-bcec7ad7afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760dc542-00a8-41ad-b73a-3df70ebe0879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
