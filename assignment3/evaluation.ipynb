{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2acd7af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8312287192686131\n",
      "Precision: 0.737807433526175\n",
      "Recall: 0.8312287192686131\n",
      "F1 Score: 0.7816509932454998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('test_set_predictions.csv')\n",
    "\n",
    "df['predictions'] = df['predictions'].apply(ast.literal_eval)\n",
    "\n",
    "#true labels starts with \"label\"\n",
    "def extract_labels(item):\n",
    "    if isinstance(item, str):\n",
    "        # If the item is a string, safely evaluate it to get the list of labels\n",
    "        labels_dict = ast.literal_eval(item)\n",
    "        return labels_dict.get('labels', labels_dict)  # Get the 'labels' list or the dict itself if 'labels' key is absent\n",
    "    elif isinstance(item, dict):\n",
    "        # If the item is a dict, return the 'labels' list\n",
    "        return item.get('labels', item)  # Get the 'labels' list or the dict itself if 'labels' key is absent\n",
    "    elif isinstance(item, list):\n",
    "        # If the item is already a list, just return it\n",
    "        return item\n",
    "    else:\n",
    "        raise ValueError(f\"The item is of unexpected type: {type(item)}. Expected string, dict, or list.\")\n",
    "\n",
    "df['true_labels'] = df['true_labels'].apply(extract_labels)\n",
    "\n",
    "# remove padding and 'None' tokens (-100) from the true labels\n",
    "flat_true_labels = [label for sublist in df['true_labels'] for label in sublist if label != -100]\n",
    "\n",
    "# remove 0 from predictions\n",
    "flat_predictions = [label for sublist, true_sublist in zip(df['predictions'], df['true_labels'])\n",
    "                    for label, true_label in zip(sublist, true_sublist) if true_label != -100]\n",
    "\n",
    "# ensure predictions and true labels have the same length\n",
    "assert len(flat_predictions) == len(flat_true_labels), \"The length of predictions and true labels should be the same.\"\n",
    "\n",
    "accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(flat_true_labels, flat_predictions, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4200ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       526\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00       586\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00        57\n",
      "           8       0.00      0.00      0.00       468\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         7\n",
      "          11       0.00      0.00      0.00        69\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.00      0.00      0.00       392\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00        67\n",
      "          19       0.00      0.00      0.00       254\n",
      "          20       0.00      0.00      0.00        52\n",
      "          21       0.00      0.00      0.00        77\n",
      "          22       0.01      0.00      0.00      1899\n",
      "          23       0.00      0.00      0.00      5110\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00        50\n",
      "          28       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00       164\n",
      "          31       0.00      0.00      0.00       259\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         9\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00        79\n",
      "          38       0.00      0.00      0.00       196\n",
      "          39       0.86      0.97      0.91     96188\n",
      "          40       0.00      0.00      0.00      3647\n",
      "          41       0.00      0.00      0.00      1285\n",
      "          42       0.00      0.00      0.00         4\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00        16\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00        29\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         8\n",
      "          54       0.00      0.00      0.00        47\n",
      "          55       0.00      0.00      0.00        12\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00       105\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00        48\n",
      "          60       0.00      0.00      0.00        82\n",
      "          61       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.83    111897\n",
      "   macro avg       0.02      0.02      0.02    111897\n",
      "weighted avg       0.74      0.83      0.78    111897\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(flat_true_labels, flat_predictions, output_dict=True)\n",
    "\n",
    "print_report = classification_report(flat_true_labels, flat_predictions)\n",
    "print(print_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
