{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:02:57.628848300Z",
     "start_time": "2024-03-02T08:02:52.567609900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token can be pasted using 'Right-Click'.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\13519\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, interpreter_login\n",
    "#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\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"token_classification_notebook\", framework=\"pytorch\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:09.167477300Z",
     "start_time": "2024-03-02T08:03:08.756115500Z"
    }
   },
   "id": "4185369c2aeddffa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:19.819027300Z",
     "start_time": "2024-03-02T08:03:19.802028300Z"
    }
   },
   "id": "37e66291332607cf"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['predicate_position', 'arguments', 'word', 'predicate'],\n        num_rows: 40482\n    })\n    test: Dataset({\n        features: ['predicate_position', 'arguments', 'word', 'predicate'],\n        num_rows: 4799\n    })\n})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "datasets = load_dataset('json', data_files={'train': 'train.json', 'test': 'test.json'})\n",
    "datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:50.718490300Z",
     "start_time": "2024-03-02T08:03:49.564125200Z"
    }
   },
   "id": "35f57dffa9a221e1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'predicate_position': 7,\n 'arguments': ['_',\n  '_',\n  '_',\n  '_',\n  '_',\n  'ARG0',\n  'V',\n  'ARG1',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  'ARGM-LOC',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_',\n  '_'],\n 'word': ['Al',\n  '-',\n  'Zaman',\n  ':',\n  'American',\n  'forces',\n  'killed',\n  'Shaikh',\n  'Abdullah',\n  'al',\n  '-',\n  'Ani',\n  ',',\n  'the',\n  'preacher',\n  'at',\n  'the',\n  'mosque',\n  'in',\n  'the',\n  'town',\n  'of',\n  'Qaim',\n  ',',\n  'near',\n  'the',\n  'Syrian',\n  'border',\n  '.'],\n 'predicate': 'kill.01'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:06.072630300Z",
     "start_time": "2024-03-02T08:04:06.055630900Z"
    }
   },
   "id": "ca1314a051618b87"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:23.990387200Z",
     "start_time": "2024-03-02T08:04:23.975385900Z"
    }
   },
   "id": "fc6fae141fbc0385"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicate_position</th>\n      <th>arguments</th>\n      <th>word</th>\n      <th>predicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>[_, _, _, _, _, _, _, _, _, ARG0, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V, _, _, _, ARGM-LOC, _, ARG2, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n      <td>[Suppose, ,, for, the, sake, of, discussion, ,, that, someone, would, openly, stay, in, a, well, -, known, address, in, Teheran, ,, hosted, by, the, Iranian, Government, and, financed, by, it, ,, executing, one, atrocity, after, another, in, Spain, or, in, France, ,, killing, hundreds, of, innocent, people, ,, accepting, responsibility, for, the, crimes, ,, promising, in, public, TV, interviews, to, do, more, of, the, same, ,, while, the, Government, of, Iran, issues, public, condemnations, of, his, acts, but, continues, to, host, him, ,, invite, him, to, official, functions, and, treat, him, as, a, great, dignitary, .]</td>\n      <td>promise.01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>[_, _, _, ARGM-ADV, _, ARG0, ARGM-MOD, ARGM-NEG, V, _, ARG1, _, _, _, _]</td>\n      <td>[Once, you, have, met, Nigel, you, will, not, want, to, work, with, anyone, else, .]</td>\n      <td>want.01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24</td>\n      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n      <td>[that, there, are, reconciling, differences, between, trader, position, analyses, ,, AS400, on, screen, enquiries, and, the, formal, global, position, report, (, these, differences, are, at, present, not, understood, but, would, need, to, be, provided, to, AA, within, the, audit, timetable, )]</td>\n      <td>be.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15</td>\n      <td>[_, _, _, _, _, _, _, _, _, _, _, _, ARG1, _, V, _, _, _, _, _, _, _, _, _]</td>\n      <td>[I, called, the, store, and, the, clerk, giggled, ,, and, agreed, that, it, was, gross, ,, but, said, it, was, not, her, problem, .]</td>\n      <td>gross.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>[_, _, _, _, ARGM-ADV, _, _, _, _, _, ARG0, ARGM-MOD, V, _, ARG1, _, ARGM-ADV, _, _]</td>\n      <td>[NOTE, :, If, i, see, a, answer, that, i, love, i, will, make, my, best, right, there, and, then]</td>\n      <td>make.01</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>36</td>\n      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARGM-TMP, _, _, _, _, ARG0, ARGM-MOD, ARGM-NEG, _, _, _, _, _, _, ARGM-LVB, _, V, _, ARGM-LOC, _, _, ARG2, _]</td>\n      <td>[2, ., I, did, not, include, a, \", Setoff, \", provision, in, this, draft, ,, mainly, because, the, vast, majority, of, the, time, ,, we, will, not, ,, nor, will, an, affiliate, ,, have, another, agreement, in, place, with, these, customers, .]</td>\n      <td>agree.01</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>22</td>\n      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG0, _, _, _, V, _]</td>\n      <td>[Hopefully, ,, if, we, 're, still, dating, come, December, ,, you, and, Chuck, can, meet, him, when, you, come, back, to, visit, .]</td>\n      <td>visit.01</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>17</td>\n      <td>[_, _, _, _, _, _, ARG1, _, _, _, _, _, _, _, _, R-ARG1, V, ARG3, _, _, _, ARGM-TMP, _, _, _, _, _]</td>\n      <td>[270, -, Estimated, number, of, court, decisions, citing, federal, Negligence, in, endangered, -, species, protection, that, remained, unheeded, during, the, first, year, of, the, Bush, administration, .]</td>\n      <td>remain.01</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>26</td>\n      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V, _, _, _, _, _, _, _]</td>\n      <td>[In, October, 2001, ,, did, the, FBI, profilers, know, of, the, draft, message, Khalid, Mohammed, had, on, the, seized, laptop, (, from, 1995, ), that, was, signed, \", Khalid, Sheik, Bojinka, \", ?]</td>\n      <td>be.03</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>[ARG0, ARGM-MOD, ARGM-ADV, V, _, _, _, ARGM-COM, _, _, ARGM-TMP, ARGM-ADV, _]</td>\n      <td>[You, should, double, check, with, the, necessary, embassy, before, you, leave, though, .]</td>\n      <td>check.01</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:29.769044100Z",
     "start_time": "2024-03-02T08:04:29.715044800Z"
    }
   },
   "id": "4a6b7ec65470697f"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:22.530273900Z",
     "start_time": "2024-03-02T09:09:22.181391900Z"
    }
   },
   "id": "237f4338dcca93b8"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:23.431553200Z",
     "start_time": "2024-03-02T09:09:23.411302100Z"
    }
   },
   "id": "2996c7fe621ae6a7"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'al', '-', 'za', '##man', ':', 'american', 'forces', 'killed', 'sha', '##ikh', 'abdullah', 'al', '-', 'an', '##i', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'q', '##ai', '##m', ',', 'near', 'the', 'syrian', 'border', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][0]\n",
    "\n",
    "sentence = example[\"word\"]\n",
    "\n",
    "\n",
    "tokenized_input = tokenizer(sentence, is_split_into_words=True)\n",
    "print(tokenized_input)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:24.745351400Z",
     "start_time": "2024-03-02T09:09:24.731350300Z"
    }
   },
   "id": "4858eeaa61a663d6"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 22, 23, 24, 25, 26, 27, 28, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:26.160324200Z",
     "start_time": "2024-03-02T09:09:26.148324700Z"
    }
   },
   "id": "94a7b34f43933b5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e12cd73680f6939f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
