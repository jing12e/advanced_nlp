{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:02:57.628848300Z",
     "start_time": "2024-03-02T08:02:52.567609900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
      "    Setting a new token will erase the existing one.\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token can be pasted using 'Right-Click'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\katko\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login, interpreter_login\n",
    "#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\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a477aefa-c62f-4d3e-8ddf-1498b8401c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\katko\\miniconda3\\lib\\site-packages (0.21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\katko\\miniconda3\\lib\\site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\katko\\miniconda3\\lib\\site-packages (from huggingface_hub) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\katko\\miniconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\katko\\miniconda3\\lib\\site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4185369c2aeddffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:09.167477300Z",
     "start_time": "2024-03-02T08:03:08.756115500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers.utils import send_example_telemetry\n",
    "\n",
    "send_example_telemetry(\"token_classification_notebook\", framework=\"pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e66291332607cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:19.819027300Z",
     "start_time": "2024-03-02T08:03:19.802028300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f57dffa9a221e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:03:50.718490300Z",
     "start_time": "2024-03-02T08:03:49.564125200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3ab3612a5c42b3b40702f11957f82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d193d464d94b4143ad48ea4b7d1eec17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['predicate', 'predicate_position', 'arguments', 'word'],\n",
       "        num_rows: 40482\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['predicate', 'predicate_position', 'arguments', 'word'],\n",
       "        num_rows: 4799\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "datasets = load_dataset('json', data_files={'train': 'train.json', 'test': 'test.json'})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c0786-4fd1-4153-9c2e-5fdb8c4779c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1314a051618b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:06.072630300Z",
     "start_time": "2024-03-02T08:04:06.055630900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predicate': 'kill.01',\n",
       " 'predicate_position': 7,\n",
       " 'arguments': ['_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARG0',\n",
       "  'V',\n",
       "  'ARG1',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  'ARGM-LOC',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_',\n",
       "  '_'],\n",
       " 'word': ['Al',\n",
       "  '-',\n",
       "  'Zaman',\n",
       "  ':',\n",
       "  'American',\n",
       "  'forces',\n",
       "  'killed',\n",
       "  'Shaikh',\n",
       "  'Abdullah',\n",
       "  'al',\n",
       "  '-',\n",
       "  'Ani',\n",
       "  ',',\n",
       "  'the',\n",
       "  'preacher',\n",
       "  'at',\n",
       "  'the',\n",
       "  'mosque',\n",
       "  'in',\n",
       "  'the',\n",
       "  'town',\n",
       "  'of',\n",
       "  'Qaim',\n",
       "  ',',\n",
       "  'near',\n",
       "  'the',\n",
       "  'Syrian',\n",
       "  'border',\n",
       "  '.']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6fae141fbc0385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:23.990387200Z",
     "start_time": "2024-03-02T08:04:23.975385900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a6b7ec65470697f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:04:29.769044100Z",
     "start_time": "2024-03-02T08:04:29.715044800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicate</th>\n",
       "      <th>predicate_position</th>\n",
       "      <th>arguments</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coordinate.01</td>\n",
       "      <td>23</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, V, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[the, stock, circularisation, initiated, for, close, of, business, 23rd, -, with, full, reconciliation, of, returns, to, current, system, data, by, traffic, /, co-ordination, an, audit, of, the, stock, and, forward, valuation, report, for, the, 30th, (, replacing, planned, 23rd, review, due, to, system, issues, ), ,, requiring, full, download, of, contract, detail, for, later, reference]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>request.01</td>\n",
       "      <td>7</td>\n",
       "      <td>[_, _, _, _, _, ARG0, V, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[His, initial, reaction, was, that, their, request, was, probably, reasonable, and, in, line, with, the, spirit, of, a, jointly, owned, L.L.C, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ensure.01</td>\n",
       "      <td>6</td>\n",
       "      <td>[ARG0, _, _, _, _, V, _, _, _, ARG1, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[Family, owned, and, operated, makes, sure, the, atmosphere, is, relaxed, and, the, food, home, -, cooked, with, style, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email.01</td>\n",
       "      <td>6</td>\n",
       "      <td>[_, _, _, _, _, V, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[If, you, have, received, this, email, in, error, ,, please, immediately, notify, the, sender, by, return, email, and, delete, this, email, from, your, system, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receive.01</td>\n",
       "      <td>3</td>\n",
       "      <td>[ARG0, _, V, _, _, ARG1, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[We, 've, received, a, personal, invitation, to, a, NYMEX, Crawfish, Boil, on, April, 3, at, 5:00, at, Garden, in, the, Heights, at, 3926, Feagan, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>be.03</td>\n",
       "      <td>2</td>\n",
       "      <td>[_, V, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[You, are, requesting, a, legitimate, service, and, you, are, paying, for, it, !!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>be.01</td>\n",
       "      <td>2</td>\n",
       "      <td>[ARG1, V, ARG2, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[Everything, was, bland, ,, completely, void, of, any, spice, or, flavor, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>make.02</td>\n",
       "      <td>13</td>\n",
       "      <td>[_, _, _, _, ARGM-TMP, ARG1, _, _, _, _, _, _, V, _, C-ARG1, _, _, _, _, _, _, _, _, _, _, _, _, _]</td>\n",
       "      <td>[22, -, Number, of, hours, prisoners, were, handcuffed, ,, shackled, ,, and, made, to, wear, surgical, masks, ,, earmuffs, ,, and, blindfolds, during, their, flight, to, Guantanamo, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>be.01</td>\n",
       "      <td>25</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARG1, V, ARGM-ADV, _, ARG2, _, _, _, _, _, _, _]</td>\n",
       "      <td>[I, have, done, a, fair, amount, of, metal, casting, ,, but, never, tried, to, build, my, own, furnace, ,, but, I, think, your, version, is, just, too, small, and, does, n't, get, hot, enough, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hoist.01</td>\n",
       "      <td>29</td>\n",
       "      <td>[_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, ARGM-ADV, _, ARG0, _, _, _, ARGM-ADV, V, ARG1, _, _, _, ARGM-MNR, _]</td>\n",
       "      <td>[The, problem, with, this, argument, is, that, Bush, lacked, the, experience, necessary, to, be, president, when, he, ran, in, 2000, ,, so, this, sort, of, cheap, shot, just, hoists, him, by, his, own, petard, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237f4338dcca93b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:22.530273900Z",
     "start_time": "2024-03-02T09:09:22.181391900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2996c7fe621ae6a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:23.431553200Z",
     "start_time": "2024-03-02T09:09:23.411302100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4858eeaa61a663d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:24.745351400Z",
     "start_time": "2024-03-02T09:09:24.731350300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "\n",
      " {'input_ids': [101, 2632, 1011, 23564, 2386, 1024, 2137, 2749, 2730, 21146, 28209, 14093, 2632, 1011, 2019, 2072, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 1053, 4886, 2213, 1010, 2379, 1996, 9042, 3675, 1012, 102, 3102, 1012, 5890, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][0]\n",
    "\n",
    "sentence = example[\"word\"]\n",
    "\n",
    "\n",
    "tokenized_input = tokenizer(sentence, is_split_into_words=True)\n",
    "predicate = example['predicate']\n",
    "predicate = tokenizer(predicate)\n",
    "\n",
    "print(tokenized_input)\n",
    "tokenized_input['input_ids'].extend(predicate['input_ids'][1:]), tokenized_input['attention_mask'].extend(predicate['attention_mask'][1:])\n",
    "\n",
    "print('\\n\\n',tokenized_input)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94a7b34f43933b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T09:09:26.160324200Z",
     "start_time": "2024-03-02T09:09:26.148324700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 22, 22, 23, 24, 25, 26, 27, 28, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12cd73680f6939f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
